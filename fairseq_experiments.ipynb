{
 "cells": [
  {
   "cell_type": "raw",
   "id": "noticed-reunion",
   "metadata": {},
   "source": [
    "!wget https://dl.fbaipublicfiles.com/fairseq/models/wmt16.en-de.joined-dict.transformer.tar.bz2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "transparent-complex",
   "metadata": {},
   "source": [
    "# Used by torch.hub.load\n",
    "!pip install sacremoses\n",
    "!pip install subword-nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "prerequisite-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import fairseq\n",
    "from fairseq.models.transformer import TransformerModel\n",
    "from fairseq.sequence_generator import EnsembleModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sized-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TEXT = 'Companies and LSPs can translate their content with the ModernMT service in many languages ' \\\n",
    "            'directly on their production environment thanks to our simple RESTful API .'\n",
    "TEST_TEXT_TARGET = 'Unternehmen und Sprachdienstleister können dank unserer einfachen RESTful API ihre ' \\\n",
    "            'Inhalte mit dem ModernMT Service in viele Sprachen direkt in ihre Produktionsumgebung übersetzen .'\n",
    "DOG_TEXT = 'I love my dog'\n",
    "test_text = TEST_TEXT  \n",
    "\n",
    "# sample = torch.Tensor([[93, 4397, 4, 491, 9971, 22, 5673, 2]])  # This is tokenised 'Hello'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "olympic-termination",
   "metadata": {},
   "source": [
    "from sacremoses import MosesTokenizer\n",
    "mt = MosesTokenizer(lang='en')\n",
    "tokenised_text = mt.tokenize(TEST_TEXT, return_str=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-corruption",
   "metadata": {},
   "source": [
    "#### Do not use `torch.hub.load` as it will likely get down latest version of Fairseq"
   ]
  },
  {
   "cell_type": "raw",
   "id": "careful-perspective",
   "metadata": {},
   "source": [
    "# List available models\n",
    "torch.hub.list('pytorch/fairseq')  # [..., 'transformer.wmt16.en-de', ... ]\n",
    "\n",
    "# Load a transformer trained on WMT'16 En-De\n",
    "# Note: WMT'19 models use fastBPE instead of subword_nmt, see instructions below\n",
    "en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt16.en-de', tokenizer='moses', bpe='subword_nmt')\n",
    "en2de.eval()  # disable dropout\n",
    "\n",
    "# The underlying model is available under the *models* attribute\n",
    "assert isinstance(en2de.models[0], fairseq.models.transformer.TransformerModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-winning",
   "metadata": {},
   "source": [
    "#### Load the downloaded translator model\n",
    "*This will actually create an instance of 'fairseq.hub_utils.GeneratorHubInterface'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "representative-observation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-05 13:17:09 | INFO | fairseq.file_utils | loading archive file model/en__it\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mmt_translation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8a35c36bc903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;34m'model/en__it'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mbpe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'subword_nmt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/models/fairseq_model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_name_or_path, checkpoint_file, data_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mdata_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0marchive_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         )\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/hub_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name_or_path, checkpoint_file, data_name_or_path, archive_map, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     models, args, task = checkpoint_utils.load_model_ensemble_and_task(\n\u001b[1;32m     71\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcpt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpathsep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0marg_overrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     )\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/checkpoint_utils.py\u001b[0m in \u001b[0;36mload_model_ensemble_and_task\u001b[0;34m(filenames, arg_overrides, task, strict, suffix, num_shards)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPathManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model file not found: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint_to_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_overrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshard_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/checkpoint_utils.py\u001b[0m in \u001b[0;36mload_checkpoint_to_cpu\u001b[0;34m(path, arg_overrides)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_overrides\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upgrade_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/checkpoint_utils.py\u001b[0m in \u001b[0;36m_upgrade_state_dict\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;31m# set any missing default values in the task, model or other registries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTASK_REGISTRY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m     \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mARCH_MODEL_REGISTRY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mregistry_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mREGISTRY\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREGISTRIES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mmt_translation'"
     ]
    }
   ],
   "source": [
    "mmt_hub_generator = TransformerModel.from_pretrained(\n",
    "  'model/en__it',\n",
    "  checkpoint_file='model.pt',\n",
    "  bpe='subword_nmt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "subjective-mouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-05 13:41:45 | INFO | fairseq.file_utils | loading archive file model/wmt16.en-de.joined-dict.transformer\n",
      "2021-02-05 13:41:56 | INFO | fairseq.tasks.translation | [en] dictionary: 32768 types\n",
      "2021-02-05 13:41:56 | INFO | fairseq.tasks.translation | [de] dictionary: 32768 types\n",
      "2021-02-05 13:41:59 | INFO | fairseq.models.fairseq_model | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_wmt_en_de_big', attention_dropout=0.1, batch_size=None, bpe='subword_nmt', bpe_codes='model/wmt16.en-de.joined-dict.transformer/bpecodes', bpe_separator='@@', clip_norm=0.0, criterion='label_smoothed_cross_entropy', cross_self_attention=False, data='/home/ubuntu/work/mmt/model/wmt16.en-de.joined-dict.transformer', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, distributed_backend='nccl', distributed_init_method='tcp://learnfair0487:59946', distributed_port=59946, distributed_rank=0, distributed_world_size=128, dropout=0.3, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu_detok='space', eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fp16=True, ignore_prefix_size=0, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, log_format='json', log_interval=10, lr=[0.001], lr_scheduler='inverse_sqrt', lr_shrink=0.1, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=3584, max_update=300000, min_lr=1e-09, momentum=0.99, no_cross_attention=False, no_epoch_checkpoints=False, no_progress_bar=False, no_save=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_batch_buckets=0, optimizer='adam', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, relu_dropout=0.0, restore_file='checkpoint_last.pt', sample_without_replacement=256000, save_dir='/checkpoint02/myleott/2018-05-18/paracrawl_en_de.fp16.maxupd300000.upsamplewmt31.samp_wo_repl256000.transformer_wmt_en_de_big.shareemb.adam.beta0.9,0.98.initlr1e-07.warmup4000.lr0.001.clip0.0.drop0.3.wd0.0.ls0.1.maxtok3584.seed2.ngpu128', save_interval=1, secondary_train_data='/private/home/myleott/data/paracrawl/en-de/paracrawl-release1.en-de.no_url.shuf_uniq_norm.scored.filtered.preprocessed', seed=2, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, source_lang='en', target_lang='de', task='translation', tie_adaptive_weights=False, train_subset='train', truncate_source=False, update_freq=[1.0], upsample_primary=31, use_old_adam=False, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0)\n"
     ]
    }
   ],
   "source": [
    "hub_generator = TransformerModel.from_pretrained(\n",
    "  'model/wmt16.en-de.joined-dict.transformer',\n",
    "  checkpoint_file='model.pt',\n",
    "  bpe='subword_nmt',  # This one is important and improves translation, without it some tokens return <unk>\n",
    "  bpe_codes='model/wmt16.en-de.joined-dict.transformer/bpecodes'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "precise-burden",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of [en2de] is <class 'fairseq.hub_utils.GeneratorHubInterface'>\n",
      "Type of [en2de.models[0]] is <class 'fairseq.models.transformer.TransformerModel'>\n"
     ]
    }
   ],
   "source": [
    "print(f'Type of [en2de] is {type(hub_generator)}')\n",
    "print(f'Type of [en2de.models[0]] is {type(hub_generator.models[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "driven-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HubTranslateWrapper(torch.nn.Module):\n",
    "    def __init__(self, generator):\n",
    "        super(HubTranslateWrapper, self).__init__()\n",
    "        self.generator = generator\n",
    "\n",
    "    def encode(self, text):\n",
    "        return self.generator.encode(text)\n",
    "    \n",
    "    def decode(self, x):\n",
    "        return self.generator.decode(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # We need to pass a text to translate\n",
    "        # We cannot return a string here, otherwise the trace fails with \"Only tensors, lists, \n",
    "        # tuples of tensors, or dictionary of tensors can be output from traced functions\"\n",
    "        return self.encode(self.generator.translate(self.decode(x)))\n",
    "    \n",
    "def benchmark(generator, encoder, decoder, test_text, times=3):\n",
    "    i = 0\n",
    "    print(f'== Running the same translation {times} times ==')\n",
    "    while i < times:\n",
    "        begin_ts = time.time()\n",
    "        decoder(generator(encoder(test_text)))\n",
    "        print('- executed in {:.6f}s'.format(time.time() - begin_ts))\n",
    "        i += 1\n",
    "        \n",
    "def benchmark_no_encode(func, test_input, times=3, batch_size=1):\n",
    "    i = 0\n",
    "    if batch_size == 1:\n",
    "        print(f'== Running single translation {times} times ==')\n",
    "    else:\n",
    "        print(f'== Running batches of {batch_size} translations {times} times ==')\n",
    "    while i < times:\n",
    "        begin_ts = time.time()\n",
    "        for j in range(batch_size):\n",
    "            func(test_input)\n",
    "        print('- executed {} translations in {:.6f}s'.format(batch_size, time.time() - begin_ts))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lucky-prescription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([26999,     9,   212,  3854,    71,    73, 18842,   113,  1306,    26,\n",
      "            6, 13994,   267,   210,   710,   457,     7,   255,  3571,  1582,\n",
      "           22,   113,   830,  1122,  2591,    12,    77,  2230, 18043,   175,\n",
      "         3111, 17819,     5,     2])\n",
      "tensor([  490,    13,  6155,  7835, 29862,   103,  4951,   363,  7588, 18043,\n",
      "          175,  3111, 17819,   233,  4195,    25,    53, 13994,   267,   210,\n",
      "          710,   990,     7,   483,  4709,  1056,     7,   233, 15578,  5716,\n",
      "        13995, 26497,     5,     2])\n"
     ]
    }
   ],
   "source": [
    "print(hub_generator.encode(TEST_TEXT))\n",
    "print(hub_generator.encode(TEST_TEXT_TARGET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "conscious-personality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Using [fairseq.hub_utils.GeneratorHubInterface.translate]:\n",
      " - Unternehmen und Sprachdienstleister können dank unserer einfachen RESTful API ihre Inhalte mit dem ModernMT Service in viele Sprachen direkt in ihre Produktionsumgebung übersetzen .\n",
      "+ Using [fairseq.hub_utils.GeneratorHubInterface.sample]:\n",
      " - Unternehmen und Sprachdienstleister können dank unserer einfachen RESTful API ihre Inhalte mit dem ModernMT Service in viele Sprachen direkt in ihre Produktionsumgebung übersetzen .\n",
      "+ Using [GeneratorHubInterfaceWrapper.forward]:\n",
      " - Unternehmen und Sprachdienstleister können dank unserer einfachen RESTful API ihre Inhalte mit dem ModernMT Service in viele Sprachen direkt in ihre Produktionsumgebung übersetzen .\n",
      " == [fairseq.hub_utils.GeneratorHubInterface.translate]\n"
     ]
    }
   ],
   "source": [
    "translated = hub_generator.translate(test_text)\n",
    "print(f'+ Using [fairseq.hub_utils.GeneratorHubInterface.translate]:\\n - {translated}')\n",
    "\n",
    "sampled = hub_generator.sample(test_text)\n",
    "print(f'+ Using [fairseq.hub_utils.GeneratorHubInterface.sample]:\\n - {sampled}')\n",
    "\n",
    "hub_translate_wrapper = HubTranslateWrapper(hub_generator)\n",
    "hub_translate_wrapper_encoded = hub_translate_wrapper.forward(hub_generator.encode(test_text))\n",
    "hub_translate_wrapper_tranlated = hub_generator.decode(hub_translate_wrapper_encoded)\n",
    "print(f'+ Using [GeneratorHubInterfaceWrapper.forward]:\\n - {hub_translate_wrapper_tranlated}')\n",
    "is_match = \"==\" if hub_translate_wrapper_tranlated == translated else \"!=\"\n",
    "print(f' {is_match} [fairseq.hub_utils.GeneratorHubInterface.translate]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "systematic-steering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Running the same translation 3 times ==\n",
      "- executed in 1.072636s\n",
      "- executed in 1.061057s\n",
      "- executed in 1.062300s\n"
     ]
    }
   ],
   "source": [
    "benchmark(hub_translate_wrapper.forward, hub_generator.encode, hub_generator.decode, test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-republican",
   "metadata": {},
   "source": [
    "#### JIT Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "handled-allowance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/torch/tensor.py:593: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  'incorrect results).', category=RuntimeWarning)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/utils.py:290: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return tensor.item()\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/data/dictionary.py:87: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if i == self.unk():\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/data/dictionary.py:47: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if idx < len(self.symbols):\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/data/dictionary.py:48: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return self.symbols[idx]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/search.py:26: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  self.src_lengths = torch.tensor(-1)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/data/data_utils.py:48: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  res = values[0].new(len(values), size).fill_(pad_idx)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/data/data_utils.py:63: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  copy_tensor(v, res[i][size - len(v) :] if left_pad else res[i][: len(v)])\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/data/language_pair_dataset.py:75: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  [s[\"source\"].ne(pad_idx).long().sum() for s in samples]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/data/language_pair_dataset.py:111: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  ntokens = src_lengths.sum().item()\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:229: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  int(self.max_len_a * src_len + self.max_len_b),\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/sinusoidal_positional_embedding.py:71: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.weights is None or max_pos > self.weights.size(0):\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:152: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert embed_dim == self.embed_dim\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:153: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert list(query.size()) == [tgt_len, bsz, embed_dim]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:270: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  [torch.jit.annotate(List[Dict[str, Tensor]], []) for i in range(bsz)],\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:274: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  False for i in range(bsz)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/models/transformer.py:787: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.cross_self_attention or prev_output_tokens.eq(self.padding_idx).any():\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:329: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert list(attn_weights.size()) == [bsz * self.num_heads, tgt_len, src_len]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:362: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert list(attn.size()) == [bsz * self.num_heads, tgt_len, self.head_dim]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:303: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert key_padding_mask.size(0) == bsz\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:304: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert key_padding_mask.size(1) == src_len\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:327: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  lprobs[lprobs != lprobs] = torch.tensor(-math.inf).to(lprobs)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/search.py:122: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  lprobs = lprobs[:, ::beam_size, :].contiguous()\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/search.py:134: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  lprobs.view(bsz, -1).size(1) - 1,  # -1 so we never select pad\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/search.py:134: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  lprobs.view(bsz, -1).size(1) - 1,  # -1 so we never select pad\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:389: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  eos_mask[:, :beam_size][cands_to_ignore] = torch.tensor(0).to(eos_mask)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:419: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert num_remaining_sent >= 0\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:420: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if num_remaining_sent == 0:\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:475: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  cand_offsets[: eos_mask.size(1)],\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:490: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert (~cands_to_ignore).any(dim=1).all()\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:433: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  ) == new_order.size(0):\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:647: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  for i in range(bbsz_idx.size()[0]):\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:653: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  sent = unfin_idx + cum_unfin[unfin_idx]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:657: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  seen = str(sent.item()) + \"_\" + str(unfin_idx.item())\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:666: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if len(finalized[sent]) < beam_size:\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:673: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  finalized[sent].append(\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:535: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  [float(elem[\"score\"].item()) for elem in finalized[sent]]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:535: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  [float(elem[\"score\"].item()) for elem in finalized[sent]]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:538: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  finalized[sent] = [finalized[sent][ssi] for ssi in sorted_scores_indices]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/hub_utils.py:172: TracerWarning: Converting a tensor to a Python list might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  for id, hypos in zip(batch[\"id\"].tolist(), translations):\n"
     ]
    }
   ],
   "source": [
    "traced_hub_translate = torch.jit.trace(hub_translate_wrapper, hub_generator.encode(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "vital-sailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Using [JIT Traced]:\n",
      " - Unternehmen und Sprachdienstleister können dank unserer einfachen RESTful API ihre Inhalte mit dem ModernMT Service in viele Sprachen direkt in ihre Produktionsumgebung übersetzen .\n",
      " == [fairseq.hub_utils.GeneratorHubInterface.translate]\n"
     ]
    }
   ],
   "source": [
    "# TODO: this does not work right, always return the same value, even if an empty tensor is given\n",
    "traced_hub_translate_encoded = traced_hub_translate(torch.Tensor([[]]))\n",
    "# traced_hub_translate_encoded = traced_hub_translate(hub_generator.encode(test_text))\n",
    "traced_hub_translate_translated = hub_generator.decode(traced_hub_translate_encoded)\n",
    "print(f'+ Using [JIT Traced]:\\n - {traced_hub_translate_translated}')\n",
    "is_match = \"==\" if traced_hub_translate_translated == translated else \"!=\"\n",
    "print(f' {is_match} [fairseq.hub_utils.GeneratorHubInterface.translate]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "considerable-transsexual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Running the same translation 5 times ==\n",
      "- executed in 0.001740s\n",
      "- executed in 0.001297s\n",
      "- executed in 0.001398s\n",
      "- executed in 0.001393s\n",
      "- executed in 0.001374s\n"
     ]
    }
   ],
   "source": [
    "benchmark(traced_generator, hub_generator.encode, hub_generator.decode, test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-specific",
   "metadata": {},
   "source": [
    "#### Trace `GeneratorHubInterface.generate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "working-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HubGenerateWrapper(torch.nn.Module):\n",
    "    def __init__(self, generator):\n",
    "        super(HubGenerateWrapper, self).__init__()\n",
    "        self.generator = generator\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.generator.generate(x)[0]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "coastal-accordance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  490,    13,  6155,  7835, 29862,   103,  4951,   363,  7588, 18043,\n",
      "          175,  3111, 17819,   233,  4195,    25,    53, 13994,   267,   210,\n",
      "          710,   990,     7,   483,  4709,  1056,     7,   233, 15578,  5716,\n",
      "        13995, 26497,     5,     2])\n"
     ]
    }
   ],
   "source": [
    "hub_generate_wrapper = HubGenerateWrapper(hub_generator)\n",
    "hub_generate_wrapper_encoded = hub_generate_wrapper.forward(hub_generator.encode(test_text))\n",
    "print(hub_generate_wrapper_encoded)\n",
    "\n",
    "# print(f'+ Using [GeneratorHubInterfaceWrapper.forward]:\\n - {hub_translate_wrapper_tranlated}')\n",
    "# is_match = \"==\" if hub_translate_wrapper_tranlated == translated else \"!=\"\n",
    "# print(f' {is_match} [fairseq.hub_utils.GeneratorHubInterface.translate]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "grand-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_hub_generate = torch.jit.trace(hub_generate_wrapper, hub_generator.encode(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "divided-transparency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  490,    13,  6155,  7835, 29862,   103,  4951,   363,  7588, 18043,\n",
       "          175,  3111, 17819,   233,  4195,    25,    53, 13994,   267,   210,\n",
       "          710,   990,     7,   483,  4709,  1056,     7,   233, 15578,  5716,\n",
       "        13995, 26497,     5,     2])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_hub_generate(hub_generator.encode(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "nominated-continent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Running the same translation 5 times ==\n",
      "- executed in 1.104018s\n",
      "- executed in 0.928745s\n",
      "- executed in 0.925975s\n",
      "- executed in 0.924407s\n",
      "- executed in 0.925427s\n"
     ]
    }
   ],
   "source": [
    "benchmark(traced_hub_generate, hub_generator.encode, hub_generator.decode, test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fails\n",
    "traced_hub_generate = torch.neuron.trace(hub_generate_wrapper, hub_generator.encode(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-address",
   "metadata": {},
   "source": [
    "#### Neuron Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cordless-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cultural-blank",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/torch/tensor.py:593: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  'incorrect results).', category=RuntimeWarning)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/utils.py:290: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return tensor.item()\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/data/dictionary.py:87: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if i == self.unk():\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/data/dictionary.py:47: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if idx < len(self.symbols):\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/data/dictionary.py:48: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return self.symbols[idx]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/search.py:26: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  self.src_lengths = torch.tensor(-1)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/data/data_utils.py:48: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  res = values[0].new(len(values), size).fill_(pad_idx)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/data/data_utils.py:63: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  copy_tensor(v, res[i][size - len(v) :] if left_pad else res[i][: len(v)])\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/data/language_pair_dataset.py:75: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  [s[\"source\"].ne(pad_idx).long().sum() for s in samples]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/data/language_pair_dataset.py:111: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  ntokens = src_lengths.sum().item()\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:229: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  int(self.max_len_a * src_len + self.max_len_b),\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/sinusoidal_positional_embedding.py:71: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.weights is None or max_pos > self.weights.size(0):\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:152: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert embed_dim == self.embed_dim\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:153: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert list(query.size()) == [tgt_len, bsz, embed_dim]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:270: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  [torch.jit.annotate(List[Dict[str, Tensor]], []) for i in range(bsz)],\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:274: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  False for i in range(bsz)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/models/transformer.py:787: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.cross_self_attention or prev_output_tokens.eq(self.padding_idx).any():\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:329: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert list(attn_weights.size()) == [bsz * self.num_heads, tgt_len, src_len]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:362: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert list(attn.size()) == [bsz * self.num_heads, tgt_len, self.head_dim]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:303: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert key_padding_mask.size(0) == bsz\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:304: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert key_padding_mask.size(1) == src_len\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:327: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  lprobs[lprobs != lprobs] = torch.tensor(-math.inf).to(lprobs)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/search.py:122: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  lprobs = lprobs[:, ::beam_size, :].contiguous()\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/search.py:134: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  lprobs.view(bsz, -1).size(1) - 1,  # -1 so we never select pad\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/search.py:134: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  lprobs.view(bsz, -1).size(1) - 1,  # -1 so we never select pad\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:389: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  eos_mask[:, :beam_size][cands_to_ignore] = torch.tensor(0).to(eos_mask)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:419: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert num_remaining_sent >= 0\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:420: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if num_remaining_sent == 0:\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:475: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  cand_offsets[: eos_mask.size(1)],\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:490: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert (~cands_to_ignore).any(dim=1).all()\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:433: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  ) == new_order.size(0):\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:647: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  for i in range(bbsz_idx.size()[0]):\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:653: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  sent = unfin_idx + cum_unfin[unfin_idx]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:657: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  seen = str(sent.item()) + \"_\" + str(unfin_idx.item())\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:666: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if len(finalized[sent]) < beam_size:\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:673: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  finalized[sent].append(\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:535: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  [float(elem[\"score\"].item()) for elem in finalized[sent]]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:535: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  [float(elem[\"score\"].item()) for elem in finalized[sent]]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:538: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  finalized[sent] = [finalized[sent][ssi] for ssi in sorted_scores_indices]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/hub_utils.py:172: TracerWarning: Converting a tensor to a Python list might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  for id, hypos in zip(batch[\"id\"].tolist(), translations):\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\nModule/Function 'GeneratorHubInterfaceWrapper' contains in-place operator aten::div_#800 with pattern view->view->inplace\nwhich cannot be automatically converted to out-of-place operators. Because compiler\nloves permuting operator execution order for the purpose of performance optimization,\nwe shamelessly ask you to rewrite your model so that it is free of in-place operators.\nFor example, the following forward function\n\n```\ndef forward(self, tensor):\n    tensor = tensor.clone()\n    torch.sigmoid_(tensor[..., :3])\n    output = torch.tanh(tensor[2:])\n    return output\n```\n\nmay be rewritten into the following\n\n```\ndef forward(self, tensor):\n    tensor = tensor.clone()\n    temp = torch.sigmoid(tensor[..., :3])\n    new_tensor = torch.cat(temp, tensor[..., 3:])\n    output = torch.tanh(new_tensor[2:])\n    return output\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-815fd54bf402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneuron_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_text_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/torch_neuron/convert.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, fallback, op_whitelist, minimum_segment_size, subgraph_builder_function, subgraph_inputs_pruning, skip_compiler, debug_must_trace, allow_no_ops_on_neuron, compiler_workdir, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# STEP 1: Translate the torch-script to a Graph object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mneuron_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_trace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mskip_compiler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/torch_neuron/convert.py\u001b[0m in \u001b[0;36mto_graph\u001b[0;34m(func_or_mod, example_inputs, return_trace)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjit_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScriptModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mneuron_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemodulize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0mneuron_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_inplace_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mneuron_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/torch_neuron/optimize.py\u001b[0m in \u001b[0;36mremove_inplace_ops\u001b[0;34m(neuron_graph)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput0_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_string\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'aten::slice'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mget_input_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput0_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_string\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mviewing_op_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mform_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'view->view->inplace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_string\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mviewing_op_types\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minplace_op_consumers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mform_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'view->inplace<-view'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nModule/Function 'GeneratorHubInterfaceWrapper' contains in-place operator aten::div_#800 with pattern view->view->inplace\nwhich cannot be automatically converted to out-of-place operators. Because compiler\nloves permuting operator execution order for the purpose of performance optimization,\nwe shamelessly ask you to rewrite your model so that it is free of in-place operators.\nFor example, the following forward function\n\n```\ndef forward(self, tensor):\n    tensor = tensor.clone()\n    torch.sigmoid_(tensor[..., :3])\n    output = torch.tanh(tensor[2:])\n    return output\n```\n\nmay be rewritten into the following\n\n```\ndef forward(self, tensor):\n    tensor = tensor.clone()\n    temp = torch.sigmoid(tensor[..., :3])\n    new_tensor = torch.cat(temp, tensor[..., 3:])\n    output = torch.tanh(new_tensor[2:])\n    return output\n```\n"
     ]
    }
   ],
   "source": [
    "neuron_generator = torch.neuron.trace(generator_wrapper, hub_generator.encode(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-graham",
   "metadata": {},
   "source": [
    "- Compilation fails with 'Module/Function 'GeneratorHubInterfaceWrapper' contains in-place operator aten::div_#800 with pattern view->view->inplace which cannot be automatically converted to out-of-place operators'\n",
    "- The same for trace of `hub_generate_wrapper`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-visiting",
   "metadata": {},
   "source": [
    "### Try to wrap the ModernMT motel into GeneratorHubInterface\n",
    "***Didn't work***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "outdoor-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "modular-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmt.checkpoint import CheckpointRegistry\n",
    "from mmt.decoder import Suggestion, ModelConfig, MMTDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "sustained-settlement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-05 11:13:44 | INFO | fairseq.tasks.translation | [sl] dictionary: 32896 types\n",
      "2021-02-05 11:13:44 | INFO | fairseq.tasks.translation | [tl] dictionary: 32896 types\n"
     ]
    }
   ],
   "source": [
    "# SequenceGenerator as a minimum needs a list of models and a target dictionary\n",
    "device = None\n",
    "config = ModelConfig.load('model')\n",
    "builder = CheckpointRegistry.Builder()\n",
    "for name, checkpoint_path in config.checkpoints:\n",
    "    builder.register(name, checkpoint_path)\n",
    "checkpoints = builder.build(device)\n",
    "mmt_generator = MMTDecoder(checkpoints, device=device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "recorded-surgery",
   "metadata": {},
   "source": [
    "prev_model = hub_generator.models[0]\n",
    "hub_generator.models[0] = mmt_generator._model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "legendary-gallery",
   "metadata": {},
   "source": [
    "hub_generator.models[0] = prev_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "demanding-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Using [GeneratorHubInterface] with ModernMT model:\n",
      " - Unternehmen und Sprachdienstleister können dank unserer einfachen RESTful API ihre Inhalte mit dem ModernMT Service in viele Sprachen direkt in ihre Produktionsumgebung übersetzen .\n"
     ]
    }
   ],
   "source": [
    "test_text = TEST_TEXT  #'I love my dog'\n",
    "mmt_translated = hub_generator.translate(test_text)\n",
    "print(f'+ Using [GeneratorHubInterface] with ModernMT model:\\n - {mmt_translated}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-morrison",
   "metadata": {},
   "source": [
    "Above blows up with \"shape '[1, -1, 32768]' is invalid for input of size 164480\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-buying",
   "metadata": {},
   "source": [
    "## Try tracing only models\n",
    "\n",
    "*Use the EN-DE model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "pointed-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelForwardEncoderWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(ModelForwardEncoderWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.model.forward_encoder({\n",
    "            'src_tokens': x, \n",
    "            'src_lengths': torch.LongTensor([t.numel() for t in x])})[0].encoder_out"
   ]
  },
  {
   "cell_type": "raw",
   "id": "guided-range",
   "metadata": {},
   "source": [
    "sample_gen_input = {\n",
    "    'net_input': {\n",
    "        'src_tokens': torch.Tensor([[9055,  9632,   518,    22, 4764, 17506,   126,   127, 15470,   144,\n",
    "                                    2242,    54,    16, 21163,  6719, 29625,  1519,    18,   278,  3580,\n",
    "                                    2352,    34,   144,  1027,   887,  1933,    20,    99,  3127,  9896,\n",
    "                                    24193,  6082, 13779,    33,    15,     2]]).long(), \n",
    "        'src_lengths': torch.Tensor([36])}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "concerned-catalyst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[26999,     9,   212,  3854,    71,    73, 18842,   113,  1306,    26,\n",
       "             6, 13994,   267,   210,   710,   457,     7,   255,  3571,  1582,\n",
       "            22,   113,   830,  1122,  2591,    12,    77,  2230, 18043,   175,\n",
       "          3111, 17819,     5,     2]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = TEST_TEXT\n",
    "test_text_encoded = hub_generator.encode(test_text)\n",
    "test_text_encoded = test_text_encoded.reshape([1, -1])\n",
    "test_text_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cardiac-think",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0653,  0.0351, -0.0476,  ...,  0.0112, -0.0564,  0.1521]],\n",
      "\n",
      "        [[-0.0361, -0.0188,  0.0328,  ..., -0.0113,  0.0097,  0.0463]],\n",
      "\n",
      "        [[-0.0060, -0.0125, -0.0390,  ...,  0.0148,  0.0915, -0.1332]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0399,  0.0138, -0.0705,  ..., -0.0054, -0.0221, -0.0650]],\n",
      "\n",
      "        [[ 0.0008,  0.0015,  0.0063,  ..., -0.0041, -0.0090, -0.0198]],\n",
      "\n",
      "        [[ 0.0008,  0.0015,  0.0063,  ..., -0.0042, -0.0090, -0.0197]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    }
   ],
   "source": [
    "model_forward_encoder_wrapper = ModelForwardEncoderWrapper(EnsembleModel([hub_generator.models[0]]))\n",
    "model_forward_encoder_wrapper_encoded = model_forward_encoder_wrapper.forward(test_text_encoded)\n",
    "print(model_forward_encoder_wrapper_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "worldwide-accountability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Running batches of 30 translations 3 times ==\n",
      "- executed 30 translations in 1.185574s\n",
      "- executed 30 translations in 1.134813s\n",
      "- executed 30 translations in 1.132835s\n"
     ]
    }
   ],
   "source": [
    "benchmark_no_encode(model_forward_encoder_wrapper.forward, test_text_encoded, batch_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-machine",
   "metadata": {},
   "source": [
    "#### JIT Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "floating-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_model_forward_encoder_wrapper = torch.jit.trace(model_forward_encoder_wrapper, test_text_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "automated-worship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0653,  0.0351, -0.0476,  ...,  0.0112, -0.0564,  0.1521]],\n",
       "\n",
       "        [[-0.0361, -0.0188,  0.0328,  ..., -0.0113,  0.0097,  0.0463]],\n",
       "\n",
       "        [[-0.0060, -0.0125, -0.0390,  ...,  0.0148,  0.0915, -0.1332]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0399,  0.0138, -0.0705,  ..., -0.0054, -0.0221, -0.0650]],\n",
       "\n",
       "        [[ 0.0008,  0.0015,  0.0063,  ..., -0.0041, -0.0090, -0.0198]],\n",
       "\n",
       "        [[ 0.0008,  0.0015,  0.0063,  ..., -0.0042, -0.0090, -0.0197]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jit_model_forward_encoder_wrapper(test_text_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "worthy-grave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Running batches of 30 translations 3 times ==\n",
      "- executed 30 translations in 1.067263s\n",
      "- executed 30 translations in 1.059980s\n",
      "- executed 30 translations in 1.063120s\n"
     ]
    }
   ],
   "source": [
    "benchmark_no_encode(jit_model_forward_encoder_wrapper, test_text_encoded, batch_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-receipt",
   "metadata": {},
   "source": [
    "#### Neuron Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "polished-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "objective-dividend",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/torch/tensor.py:593: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  'incorrect results).', category=RuntimeWarning)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/sinusoidal_positional_embedding.py:71: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.weights is None or max_pos > self.weights.size(0):\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:152: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert embed_dim == self.embed_dim\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:153: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert list(query.size()) == [tgt_len, bsz, embed_dim]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Please implement aten::Bool in native_ops/aten.py",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-4badc86f330b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneuron_model_forward_encoder_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_forward_encoder_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_text_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/torch_neuron/convert.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, fallback, op_whitelist, minimum_segment_size, subgraph_builder_function, subgraph_inputs_pruning, skip_compiler, debug_must_trace, allow_no_ops_on_neuron, compiler_workdir, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# STEP 1: Translate the torch-script to a Graph object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mneuron_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_trace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mskip_compiler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/torch_neuron/convert.py\u001b[0m in \u001b[0;36mto_graph\u001b[0;34m(func_or_mod, example_inputs, return_trace)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjit_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScriptModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0minput_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjit_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mneuron_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll_call_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0mneuron_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_call_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscript_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mneuron_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/torch_neuron/optimize.py\u001b[0m in \u001b[0;36munroll_call_method\u001b[0;34m(neuron_graph, input_list)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mjit_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_input_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mmodule_neuron_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mmodule_neuron_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_jit_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjit_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0mmodule_neuron_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munroll_call_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_neuron_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_input_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mmodule_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallMethodOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}#{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjit_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/torch_neuron/graph.py\u001b[0m in \u001b[0;36mimport_jit_graph\u001b[0;34m(self, jit_graph)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mjit_node\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjit_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_jit_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjit_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_uniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjit_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/torch_neuron/graph.py\u001b[0m in \u001b[0;36mimport_jit_node\u001b[0;34m(self, jit_node)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjit_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjit_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimport_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/torch_neuron/resolve_function.py\u001b[0m in \u001b[0;36mget_function\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauto_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_implemented\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mfunc_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_aten_func_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresolved_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Please implement aten::Bool in native_ops/aten.py"
     ]
    }
   ],
   "source": [
    "neuron_model_forward_encoder_wrapper = torch.neuron.trace(model_forward_encoder_wrapper, test_text_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-isaac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_neuron_env",
   "language": "python",
   "name": "torch_neuron_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
