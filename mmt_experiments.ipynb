{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source test_speed_cpu.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unsigned-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "numeric-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.neuron\n",
    "\n",
    "from mmt import utils\n",
    "from mmt.checkpoint import CheckpointRegistry\n",
    "from mmt.decoder import Suggestion, ModelConfig, MMTDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "identical-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TEXT = 'Companies and LSPs can translate their content with the ModernMT service in many languages ' \\\n",
    "            'directly on their production environment thanks to our simple RESTful API .'\n",
    "MODEL_DIR = 'model'\n",
    "device=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "three-influence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-29 16:16:24 | INFO | fairseq.tasks.translation | [sl] dictionary: 32896 types\n",
      "2021-01-29 16:16:24 | INFO | fairseq.tasks.translation | [tl] dictionary: 32896 types\n",
      "2021-01-29 16:16:27 | INFO | Transformer | reset_time = 0.063, tune_time = 0.000, decode_time = 1.163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le aziende e i LSP possono tradurre il loro contenuto con il servizio di modernit√† in molte lingue direttamente nel loro ambiente di produzione grazie alla nostra semplice API .\n",
      "[(0, 0), (0, 1), (1, 2), (2, 4), (3, 5), (4, 6), (5, 7), (5, 8), (6, 9), (7, 10), (8, 11), (9, 13), (9, 14), (10, 12), (11, 15), (12, 16), (13, 17), (14, 18), (15, 19), (16, 20), (17, 22), (17, 23), (18, 21), (19, 24), (20, 24), (21, 25), (22, 26), (23, 27), (24, 28)]\n"
     ]
    }
   ],
   "source": [
    "config = ModelConfig.load(MODEL_DIR)\n",
    "builder = CheckpointRegistry.Builder()\n",
    "for name, checkpoint_path in config.checkpoints:\n",
    "    builder.register(name, checkpoint_path)\n",
    "checkpoints = builder.build(device)\n",
    "decoder = MMTDecoder(checkpoints, device=device, tuning_ops=config.tuning)\n",
    "decoder._nn_needs_reset = True\n",
    "translation = decoder.translate('en', 'it', [TEST_TEXT], None)[0]\n",
    "\n",
    "print(translation.text)\n",
    "print(translation.alignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-blocking",
   "metadata": {},
   "source": [
    "## Attempt to compile the `decoder` object\n",
    "It is using `fairseq` classes internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "norman-factor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of `decoder._model`: <class 'fairseq.models.transformer.TransformerModel'>\n",
      "Type of `decoder._translator`: <class 'fairseq.sequence_generator.SequenceGenerator'>\n",
      "Type of `decoder._tuner`: <class 'mmt.tuning.Tuner'>\n"
     ]
    }
   ],
   "source": [
    "print(f'Type of `decoder._model`: {type(decoder._model)}')\n",
    "print(f'Type of `decoder._translator`: {type(decoder._translator)}')\n",
    "print(f'Type of `decoder._tuner`: {type(decoder._tuner)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "occupied-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGen(torch.nn.Module):\n",
    "    def __init__(self, model, translator):\n",
    "        super(MyGen, self).__init__()\n",
    "        self.model = model\n",
    "        self.translator = translator\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.translator.generate([self.model], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thrown-tissue",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:229: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  int(self.max_len_a * src_len + self.max_len_b),\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/sinusoidal_positional_embedding.py:71: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.weights is None or max_pos > self.weights.size(0):\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:152: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert embed_dim == self.embed_dim\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:153: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert list(query.size()) == [tgt_len, bsz, embed_dim]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:270: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  [torch.jit.annotate(List[Dict[str, Tensor]], []) for i in range(bsz)],\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:274: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  False for i in range(bsz)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/models/transformer.py:787: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.cross_self_attention or prev_output_tokens.eq(self.padding_idx).any():\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:329: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert list(attn_weights.size()) == [bsz * self.num_heads, tgt_len, src_len]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:362: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert list(attn.size()) == [bsz * self.num_heads, tgt_len, self.head_dim]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:303: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert key_padding_mask.size(0) == bsz\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:304: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert key_padding_mask.size(1) == src_len\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:327: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  lprobs[lprobs != lprobs] = torch.tensor(-math.inf).to(lprobs)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/search.py:122: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  lprobs = lprobs[:, ::beam_size, :].contiguous()\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/search.py:134: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  lprobs.view(bsz, -1).size(1) - 1,  # -1 so we never select pad\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/search.py:134: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  lprobs.view(bsz, -1).size(1) - 1,  # -1 so we never select pad\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:389: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  eos_mask[:, :beam_size][cands_to_ignore] = torch.tensor(0).to(eos_mask)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:419: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert num_remaining_sent >= 0\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:420: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if num_remaining_sent == 0:\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:475: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  cand_offsets[: eos_mask.size(1)],\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:490: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert (~cands_to_ignore).any(dim=1).all()\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/modules/multihead_attention.py:433: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  ) == new_order.size(0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:647: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  for i in range(bbsz_idx.size()[0]):\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:653: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  sent = unfin_idx + cum_unfin[unfin_idx]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:657: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  seen = str(sent.item()) + \"_\" + str(unfin_idx.item())\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:666: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if len(finalized[sent]) < beam_size:\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:673: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  finalized[sent].append(\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:535: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  [float(elem[\"score\"].item()) for elem in finalized[sent]]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:535: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  [float(elem[\"score\"].item()) for elem in finalized[sent]]\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/torch/tensor.py:593: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  'incorrect results).', category=RuntimeWarning)\n",
      "/home/ubuntu/work/torch_neuron_env/lib/python3.7/site-packages/fairseq/sequence_generator.py:538: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  finalized[sent] = [finalized[sent][ssi] for ssi in sorted_scores_indices]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-588c0fafbe21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_decode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTEST_TEXT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmy_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyGen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_translator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/torch_neuron/convert.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, fallback, op_whitelist, minimum_segment_size, subgraph_builder_function, subgraph_inputs_pruning, skip_compiler, debug_must_trace, allow_no_ops_on_neuron, compiler_workdir, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# STEP 1: Translate the torch-script to a Graph object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mneuron_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_trace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mskip_compiler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/torch_neuron/convert.py\u001b[0m in \u001b[0;36mto_graph\u001b[0;34m(func_or_mod, example_inputs, return_trace)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munify_example_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrack_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscript_tracker\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mjit_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     original_name = getattr(jit_trace, 'original_name',\n\u001b[1;32m    224\u001b[0m                             getattr(jit_trace, 'name', None))\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0m_module_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m         )\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/torch_neuron_env/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    938\u001b[0m                 \u001b[0mvar_lookup_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                 \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m             )\n\u001b[1;32m    942\u001b[0m             \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions"
     ]
    }
   ],
   "source": [
    "# Attempt to trace\n",
    "batch, input_indexes, sentence_len = decoder._make_decode_batch([TEST_TEXT], prefix_lang=None)\n",
    "my_gen = MyGen(decoder._model, decoder._translator)\n",
    "torch.neuron.trace(my_gen, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-typing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_neuron_env",
   "language": "python",
   "name": "torch_neuron_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
